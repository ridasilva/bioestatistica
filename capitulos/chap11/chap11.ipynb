{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75656e5c-2d7e-468f-9fd3-78ccb9c2b501",
   "metadata": {},
   "source": [
    "# 11 - ANOVA de um fator para amostras independentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22959209-89cd-46c1-b02c-7bfa3729ffde",
   "metadata": {},
   "source": [
    "Este material foi traduzido e adaptado de {cite}`carlson2017introduction`.\n",
    "\n",
    "OBJETIVOS DE APRENDIZADO\n",
    "\n",
    "Depois de ler este capítulo, você será capaz de fazer o seguinte:\n",
    "\n",
    "- Identificar quando usar uma ANOVA de amostras independentes;\n",
    "- Explicar a lógica da razão F para ANOVA; \n",
    "- Explicar como o erro de medição, as diferenças individuais e os efeitos do tratamento influenciam o numerador e o denominador da razão F;\n",
    "- Escrever hipóteses nulas e de pesquisa usando símbolos e palavras;\n",
    "- Preencha uma tabela de resumo da ANOVA calculando os graus de liberdade, SQs, QMs e razão F;\n",
    "- Defina uma região crítica e determine se você deve rejeitar ou não rejeitar a hipótese nula;\n",
    "- Calcular tamanhos de efeito e descrevê-los;\n",
    "- Explicar quando e por que os testes post hoc são necessários;\n",
    "- Resumir os resultados de uma ANOVA de amostras independentes;\n",
    "- Usar software para calcular uma ANOVA de amostras independentes, incluindo testes _post hoc_;\n",
    "- Interpretar a saída do software para uma ANOVA de amostras independentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d72a52-30be-411c-bb78-abda461a8c5d",
   "metadata": {},
   "source": [
    "## ANOVA de amostras independentes\n",
    "\n",
    "O teste t de amostras independentes e o teste t de amostras relacionadas comparam duas médias amostrais para determinar se seu desvio é maior do que seria esperado pelo erro amostral. Ambos os testes t compartilham uma limitação importante, pois só podem comparar duas médias amostrais por vez. Uma ANOVA é substancialmente mais flexível, pois pode comparar duas ou mais médias amostrais ao mesmo tempo para determinar se o desvio entre qualquer par de médias amostrais é maior do que seria esperado pelo erro amostral. Portanto, uma única ANOVA, também conhecida como ANOVA unidirecional ou ANOVA de fator único, pode comparar dois tratamentos (por exemplo, Tratamento A e Tratamento B) entre si, bem como comparar cada um desses tratamentos com uma condição de controle (por exemplo, placebo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b7a17-e25d-4fbc-ad7c-2108996e7a51",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "from jupyterquiz import display_quiz\n",
    "#display_quiz(\"questions.json\", preserve_responses = True)\n",
    "display_quiz(\"question1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40300e1a-dca7-424b-aa8a-9300b6921a4c",
   "metadata": {},
   "source": [
    "## Outros nomes\n",
    "\n",
    "ANOVA é uma abreviatura para Análise de Variância. Uma ANOVA independente, assim como um teste t independente , é usada quando há pessoas diferentes em cada condição do projeto. Por exemplo, se houvesse três tratamentos diferentes que você desejasse comparar em um desenho de amostras independentes, algumas pessoas receberiam o Tratamento A, outras o Tratamento B e o restante o Tratamento C. Este tipo de desenho também é conhecido como desenho entre sujeitos ou um projeto de medidas independentes. Uma ANOVA de amostras relacionadas, assim como um teste t de amostras relacionadas , é usada quando as médias amostrais são geradas pela mesma amostra ou por amostras correspondentes. ANOVAs de amostras independentes e ANOVAs de amostras relacionadas que envolvem apenas uma variável categórica (por exemplo, uma variável independente, VI) são frequentemente chamadas de ANOVAs de um fator. Neste livro, discutiremos apenas ANOVAs de amostras independentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674d524-48e5-45ae-85f6-74e188af1533",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca208d85-73d5-4390-822c-a7ff58aa77e6",
   "metadata": {},
   "source": [
    "## Lógica da ANOVA\n",
    "\n",
    "Todos os testes de significância que você aprendeu até agora (isto é, z para uma média amostral, teste t para amostra única, teste t para amostras independentes e o teste t para amostras relacionadas) compartilham uma lógica comum. Ou seja, para todos eles, você calculou a diferença observada entre duas médias e depois dividiu essa diferença pela diferença que seria esperada devido ao erro amostral. A lógica do teste ANOVA é diferente. Como provavelmente fica evidente pelo nome, uma análise de variância analisa a variância das observações. Especificamente, uma ANOVA analisa a variância das observação entre e dentro das condições da VI, numa tentativa de determinar se as diferentes condições de tratamento afetam os valores de forma diferente. Por exemplo, você poderia usar uma ANOVA para determinar se três condições de tratamento diferentes levam a diferentes valores de depressão. Para compreender a lógica das ANOVAs, você deve entender que três coisas afetam a variância das observações:\n",
    "\n",
    "1. Erro de medição: Sempre haverá variação nas observações entre as unidades amostrais porque as variáveis não podem ser medidas perfeitamente.\n",
    "\n",
    "2. Diferenças individuais: Sempre haverá variação nas observações entre as unidades amostrais porque as unidades são naturalmente diferentes entre si.\n",
    "\n",
    "3. Efeito do tratamento: Pode haver variação nas observações entre os grupos porque estes experimentaram diferentes condições (VI) ou tratamentos.\n",
    "\n",
    "As duas primeiras fontes de variância nas observações, erro de medição e diferenças individuais, estarão sempre presentes. Essas duas fontes de variação são frequentemente chamadas coletivamente de variação de erro porque ambos são componentes do erro amostral. A terceira fonte de variação é realmente o que interessa aos pesquisadores. Os pesquisadores usam a ANOVA para estimar a quantidade de variação das observações criada pelas diferentes condições de tratamento (VI). Ao realizar as atividades deste capítulo, você poderá entender isso melhor. Por enquanto, você tem informações suficientes para entender a lógica da ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b6f77-98ea-4f83-9a3f-127389f4b864",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3622866-ebaf-409d-ac55-23e172852c44",
   "metadata": {},
   "source": [
    "A ANOVA analisa as quantidades relativas dessas três fontes de variabilidade das observações – a saber, (1) efeitos de tratamento, (2) diferenças individuais e (3) erro de medição – para produzir uma estatística F. A fórmula conceitual da ANOVA é uma razão entre a variabilidade entre as condições de tratamento e a variabilidade dentro das condições de tratamento. Duas representações da fórmula conceitual para uma ANOVA independente são mostradas a seguir:\n",
    " \n",
    "$F = \\frac{Variabilidade\\quad entre\\quad condições\\quad de\\quad tratamento}{Variabilidade\\quad dentro\\quad das\\quad condições\\quad de\\quad tratamento}$\n",
    " \n",
    "$F = \\frac{Efeito\\quad do\\quad tratamento\\quad \\&\\quad diferenças\\quad individuais\\quad \\&\\quad erro\\quad de\\quad medição}{Diferenças\\quad individuais\\quad \\&\\quad Erro\\quad de\\quad medição}$\n",
    "\n",
    "O numerador da razão F é a variabilidade nas observações que existe entre os diferentes grupos de tratamento (ou seja, condições da VI), que é chamada de variabilidade entre grupos ou variabilidade entre tratamentos. Por exemplo, se uma condição tivesse valores observados altos e outra condição tivesse valores observados baixos, haveria muita variabilidade entre grupos. No entanto, se todas as condições tivessem valores semelhantes, haveria pouca variabilidade entre grupos. Existem três fontes possíveis para a variabilidade entre tratamentos. É possível que os diferentes tratamentos criem variabilidade entre grupos porque um tratamento é mais eficaz que outro (ou seja, os tratamentos afectam a variável dependente de forma diferente). Esta é a variabilidade na qual os investigadores estão mais interessados. No entanto, alguma da variabilidade entre grupos é sempre causada por diferenças individuais e erros de medição. Assim, o numerador da razão F, a variabilidade entre grupos, consiste em efeitos de tratamento, efeitos de diferenças individuais e erro de medição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2fbbd-a2b8-4c6c-8594-c7349050706f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a434c-fcce-4010-a9ea-f37462f64317",
   "metadata": {},
   "source": [
    "O denominador da razão F é a variabilidade nas observações que existe dentro dos grupos de tratamento (isto é, condições da VI), que é chamada de variabilidade dentro do grupo. Existem duas fontes possíveis para a variabilidade intratratamento: (1) diferenças individuais e (2) erro de medição. É importante notar que as diferenças nas observações dentro de cada condição de tratamento não são causadas por diferenças na eficácia do tratamento porque todas as pessoas dentro de um determinado grupo experimentaram o mesmo tratamento. As únicas fontes de diferenças dentro de uma condição de tratamento são diferenças individuais e erros de medição. O denominador da razão F é frequentemente chamado de termo de erro porque contém apenas a variância criada pelo erro de amostragem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35d22a-0a6b-48f1-878f-fb021501d984",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question5.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5fb7f-bc6b-4261-9386-6e3d2a147e8f",
   "metadata": {},
   "source": [
    "Se você observar as fontes de variação no numerador e no denominador da ANOVA independente, poderá ver que a única diferença é que o numerador inclui efeitos de tratamento e o denominador não. Este fato é crítico para a lógica da ANOVA independente. Imagine uma situação em qual o efeito do tratamento cria variância zero (ou seja, o tratamento não funciona). Se você substituir \"efeito do tratamento\" na fórmula conceitual por \"0\", a equação seria a seguinte:\n",
    "\n",
    "$F = \\frac{0\\quad \\&\\quad diferenças\\quad individuais\\quad \\&\\quad erro}{Diferenças\\quad individuais\\quad \\&\\quad erro}$\n",
    "\n",
    "Com a variância do efeito do tratamento sendo zero, a razão F seria igual a 1 porque o numerador e o denominador seriam o mesmo número. Portanto, se o tratamento não criar variabilidade nas observações, espera-se que a ANOVA produza um valor estatístico F próximo de 1. Por outro lado, se os diferentes tratamentos criarem muita variabilidade nas pontuações, espera-se que o valor F seja substancialmente maior que 1. Um valor ANOVA F não pode ser negativo porque é a razão de duas variâncias, e as variâncias devem ser positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa56ace-36b1-4e1c-8b76-bd061ff0ee67",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question5.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f40bde-1b6d-4bd5-aedf-1a72d8467939",
   "metadata": {},
   "source": [
    "## Um exemplo de problema para ANOVA\n",
    "\n",
    "Você usa uma ANOVA de amostras independentes para comparar as médias de dois ou mais grupos/amostras contendo unidades amostrais diferentes. Por exemplo, suponha que você queira comparar a terapia cognitivo-comportamental (TCC) e a terapia psicodinâmica (TPD) como tratamentos para a depressão. Você identifica uma amostra de pessoas com depressão grave e as divide aleatoriamente em três grupos diferentes. Um grupo é submetido à TCC por 6 meses, um segundo grupo é submetido à TPD por 6 meses e um terceiro grupo funciona como grupo controle e não recebe tratamento (NT). Após 6 meses, você avalia os níveis de depressão usando o Inventário de Depressão de Beck (BDI; os valores variam de 0 a 63), com pontuações mais altas indicando maior depressão. Os valores de depressão encontrados para cada grupo estão listados na Tabela 11.1. Neste estudo, a VI é o tipo de tratamento (TCC, TPD ou TN) e a VD (variável dependente) é o valor de depressão de cada pessoa na escala BDI.\n",
    "\n",
    "_Tabela 11.1 - Valores de depressão após três tipos diferentes de tratamento_\n",
    "\n",
    " Grupo 1 | Grupo 2 | Grupo 3\n",
    " -- | -- | --\n",
    "  **Terapia cognitiva comportamental** | **Terapia Psicodinâmica** | **Controle - sem de tratamento**\n",
    " 5 | 16 | 14\n",
    " 9 | 17 | 19\n",
    " 11 | 18 | 16\n",
    " 6 | 13 | 9\n",
    " 2 | 10 | 15\n",
    " 15 | 19 | 25\n",
    " $\\bar{x}_1 = 8.00$ | $\\bar{x}_2 = 15.50$ | $\\bar{x}_3 = 16.333$\n",
    " $DP_1 = 4.65$ | $DP_2 = 3.39$ | $DP_3 = 5.35$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb625ab-89b5-40df-85cf-65f417c4d12a",
   "metadata": {},
   "source": [
    "### Etapa 1: examinar variáveis para avaliar suposições estatísticas\n",
    "\n",
    "As suposições estatísticas para testes t independentes e ANOVAs independentes são idênticas. Portanto, você deve considerar quatro suposições. No seu estudo, os valores de depressão dos indivíduos devem ser medidos sem que a medição de um participante influencie o de outro (independência de dados). Sua VD, pontuação de depressão, deve ser medida como uma variável quantitativa, e seu VI deve identificar como os três tratamentos terapêuticos são diferentes (medição apropriada de variáveis para ANOVA independente). A distribuição das médias amostrais para cada uma de suas condições deve ter uma forma normal (normalidade). Como foi o caso de alguns exemplos anteriores, os tamanhos amostrais neste estudo (ns = 6) são demasiado pequenos para se ter certeza de que as distribuições das médias amostrais terão uma forma normal, a menos que as populações originais tenham uma forma normal. Você deve tentar obter tamanhos de amostra próximos a 30 participantes por condição (ou seja, perto de 90 participantes no total neste caso). Mas, para fins didáticos, esses tamanhos de amostra menores funcionarão bem. Sua quarta suposição é a homogeneidade de variância. Para ANOVAs, retorne à regra do duplo desvio padrão; se qualquer uma de suas condições tiver um desvio padrão o dobro de outra, a suposição de homogeneidade de variância pode ser violada. Embora existam maneiras de testar variâncias iguais na ANOVA (ver Field, 2013), as ANOVAs são geralmente bastante robustas a violações desta suposição, desde que os tamanhos das amostras sejam aproximadamente iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541365e-987f-4c97-a393-a1df83f68ecc",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question6.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d99b9-8d0d-4c1a-a8f6-106b84c15d44",
   "metadata": {},
   "source": [
    "### Etapa 2: expor as hipóteses nulas e de pesquisa\n",
    "\n",
    "Sua segunda etapa é estabelecer as hipóteses nula e de pesquisa. A hipótese nula sempre afirma que todas as populações têm os mesmos valores médios da VD. Nesse caso, a hipótese nula afirma que as três populações de pessoas estudadas (isto é, aquelas que recebem TCC, TPD ou TN) têm os mesmos valores médios de depressão; quaisquer diferenças observadas nas amostras são devidas a erros amostrais. Em contraste, a hipótese de investigação afirma que os valores médios da VD das três populações não são iguais.\n",
    "Neste caso, a hipótese de investigação afirma que pelo menos uma dos valores médios de depressão das populações é significativamente diferente de pelo menos uma das outras. Observe que a hipótese de pesquisa não especifica que todas as médias da população são diferentes, apenas que pelo menos uma média da população é diferente de pelo menos uma dos outros. A hipótese da pesquisa diz que um ou mais dos tratamentos funcionam melhor do que um ou mais dos outros. A Tabela 11.2 resume como escrever as hipóteses nula e de pesquisa.\n",
    "\n",
    "Tipo de Hipótese | Simbólico | Vebal | Diferença entre médias amostral e populacional\n",
    "-- | -- | -- | --\n",
    " Hipótese nula | $H_0:\\mu_1=\\mu_2=...=\\mu_K;$ | Médias $\\approx$ para todas populações | Erro amostral\n",
    " Hipótese de pesquisa | $H_a:\\mu_i \\neq \\mu_j.$ | Médias $\\neq$ para pelo menos um par | Um ou mais tratamentos têm efeito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fedccab-d0a7-4f9d-a52f-177d78f822e8",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question7.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790f793-9618-4ae7-b8de-059ef010affa",
   "metadata": {},
   "source": [
    "### Etapa 3: Definir o valor crítico de F\n",
    "\n",
    "Tal como acontece com os testes t, você usa um valor crítico para determinar se deve rejeitar o nulo, mas precisará de dois valores gl diferentes para encontrar o valor crítico de F. Você precisará de um valor gl baseado no número de participantes e outro valor gl baseado no número de grupos. Se a hipótese nula for verdadeira, o valor F obtido deve estar próximo de 1. Se a hipótese nula for falsa, o valor F obtido deve ser muito maior que 1. Mas a que distância de 1 um valor F deve estar para rejeitar a hipótese nula? Se o valor F for igual ou maior que o valor F crítico, você rejeita a hipótese nula.\n",
    "\n",
    "Especificamente, você precisará dos graus de liberdade entre tratamentos (gl_entre) e dos graus de liberdade dentro dos tratamentos (gl_dentro(error)) para encontrar o valor F crítico. Esses gls são calculados com as seguintes fórmulas, respectivamente:\n",
    "\n",
    "gl_entre = g - 1, entre onde g representa o número de grupos/condições de tratamento, e\n",
    "\n",
    "gl_dentro = N-g , onde N representa o número de valores em estudo inteiro.\n",
    "\n",
    "Neste caso, o gl_entre = 3 - 1 = 2, e o gl_dentro = 18 - 3 = 15. Você usa esses valores gl para encontrar o valor crítico de F no Apêndice C. O Apêndice C contém valores críticos para níveis alfa de 0.05 e 0.01 em duas tabelas separadas. O gl_entre (neste caso, 2) indica a coluna, e o gl_dentro (neste caso, 15) indica a linha para encontrar o valor crítico de F. Conforme ilustrado na Figura 11.1, o valor crítico de F quando os dfs são 2 e 15 e usando um valor alfa de 0.05 é 3.68. Portanto, se o valor F observado fosse maior que 3.68, você rejeita a hipótese nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a70fb20-2184-4ed1-973d-3a6bcd0197d4",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e3672_row1_col0, #T_e3672_row1_col1, #T_e3672_row1_col2 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e3672\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e3672_level0_col0\" class=\"col_heading level0 col0\" >1</th>\n",
       "      <th id=\"T_e3672_level0_col1\" class=\"col_heading level0 col1\" >2</th>\n",
       "      <th id=\"T_e3672_level0_col2\" class=\"col_heading level0 col2\" >3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e3672_level0_row0\" class=\"row_heading level0 row0\" >14</th>\n",
       "      <td id=\"T_e3672_row0_col0\" class=\"data row0 col0\" >4.600100</td>\n",
       "      <td id=\"T_e3672_row0_col1\" class=\"data row0 col1\" >4.543100</td>\n",
       "      <td id=\"T_e3672_row0_col2\" class=\"data row0 col2\" >4.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3672_level0_row1\" class=\"row_heading level0 row1\" >15</th>\n",
       "      <td id=\"T_e3672_row1_col0\" class=\"data row1 col0\" >3.738900</td>\n",
       "      <td id=\"T_e3672_row1_col1\" class=\"data row1 col1\" >3.682300</td>\n",
       "      <td id=\"T_e3672_row1_col2\" class=\"data row1 col2\" >3.633700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e3672_level0_row2\" class=\"row_heading level0 row2\" >16</th>\n",
       "      <td id=\"T_e3672_row2_col0\" class=\"data row2 col0\" >3.343900</td>\n",
       "      <td id=\"T_e3672_row2_col1\" class=\"data row2 col1\" >3.287400</td>\n",
       "      <td id=\"T_e3672_row2_col2\" class=\"data row2 col2\" >3.238900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x788efa1c4700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDE CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "gl_entre = [1, 2, 3]\n",
    "gl_dentro = [14, 15, 16]\n",
    "\n",
    "a05 = []\n",
    "for i in gl_entre:\n",
    "    tmp = []\n",
    "    for j in gl_dentro:\n",
    "        tmp.append(round(stats.f(i, j).ppf(0.95), 4))\n",
    "    a05.append(tmp)\n",
    "\n",
    "df = pd.DataFrame(a05, columns=gl_entre, index=gl_dentro)\n",
    "\n",
    "color = (df.iloc[:,1] == df.iloc[1,1]).map({True: 'background-color: yellow', False: ''})\n",
    "\n",
    "df.style.apply(lambda s: color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861392e-25d5-4c96-94f7-fab62c0bfcd4",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question8.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb7a809-59a5-4c9f-a925-58112569e34d",
   "metadata": {},
   "source": [
    "### Etapa 4: Calculando a estatística do teste (ANOVA independente)\n",
    "\n",
    "_4a–4d. Completando a Tabela Resumo da ANOVA_\n",
    "\n",
    "Para calcular a razão F , você precisa calcular dois números: (1) a variância entre as condições de tratamento e (2) a variância dentro das condições de tratamento. Neste livro, até agora, você geralmente calculou o desvio padrão para medir a variabilidade. No entanto, ao fazer uma ANOVA, você calcula a variância como uma medida de variabilidade. Você deve se lembrar que a variância da amostra é o desvio médio quadrático das observações em relação à média e é calculada dividindo a SQ pelo seu gl. Na terminologia ANOVA, a variância é referida como quadrado médio (abreviado como QM). Embora a terminologia seja um pouco diferente, a lógica é a mesma. Para calcular cada QM, você divide cada SQ por seu gl. Esses cálculos são normalmente feitos usando um pacote de _software_ (por exemplo, Google Sheet), e os resultados são frequentemente apresentados em uma tabela fonte ANOVA. Uma tabela de origem ANOVA é um resumo valioso da análise estatística ANOVA porque mostra como o F obtido é criado. A tabela de origem lista as fontes de variação discutidas nas seções anteriores, entre e dentro dos tratamentos, na primeira coluna. Os títulos das colunas indicam as etapas necessárias para calcular um F: SQ, gl, QM e, finalmente, F. A Tabela 11.3 é uma tabela fonte da ANOVA. As fórmulas para gl, SQ, F e $\\eta^2$ são apresentadas porque a melhor maneira de entender as inter-relações entre esses termos é ver como cada valor é gerado. A $SQ_{entre}$ representa a soma da variabilidade criada pelo efeito do tratamento, diferenças individuais e erro de medição. Você calcula o $SQ_{entre}$ calculando a SQ para as médias dos três grupos e depois multiplicando esse valor $SQ_{medias}$ por _m_ (ou seja, o número de unidades amostrais em cada grupo). Nesse caso, as médias dos três grupos são 8.0, 15.5 e 16.3333, respectivamente. Portanto, seu $SQ_{media}$ é a SQ destas três médias:\n",
    "\n",
    "Tratamento | Média ($\\bar{Y}_i$) | $\\bar{Y}_i^2$\n",
    "-- | -- | --\n",
    "TCC | 8 | 64\n",
    "TPD | 15.5 | 240.25\n",
    "TN  | 16.333 | 266.777\n",
    "-|$\\bar{Y}=13.6$| $\\sum_{i=1}^K\\bar{Y}_i^2 = 571.027$\n",
    "\n",
    "$SQE = m \\sum_{i=1}^K(\\bar{Y}_i-\\bar{Y})^2 = m(\\sum_{i=1}^K\\bar{Y}_i^2-K\\bar{Y}^2)$\n",
    "\n",
    "$SQE =  6 \\times (571.027- 3\\times 13.278^2) = 252.667$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34eb1f8-b2a3-47f2-9f28-8853364bcda1",
   "metadata": {},
   "source": [
    "A fórmula acima para $SQE$ só funciona quando há um número igual de unidades amostrais em cada condição de tratamento. Em situações onde os tamanhos amostrais não são iguais, seria necessária uma fórmula computacional diferente, mas a lógica do SQentre ainda é a mesma. O valor resultante representa a variabilidade criada pelas diferentes condições de tratamento, diferenças individuais e erros de medição. Não apresentamos aqui a fórmula computacional necessária quando há tamanhos de amostra desiguais. Estamos mais interessados na sua compreensão da lógica da ANOVA e em como interpretar seus resultados do que na sua capacidade de calcular uma ANOVA com tamanhos de amostra desiguais a partir de dados brutos.\n",
    "\n",
    "Agora que você tem seu $SQE$, o próximo passo é encontrar o $SQD$. O $SQD$ é a soma da variabilidade criada pelas diferenças individuais e erros de medição dentro de cada condição. Você encontra o $SQD$ calculando o SQ para cada condição de tratamento separadamente e depois somando-os.\n",
    "\n",
    "$SQD = \\sum_{i=1}^K\\sum_{j=1}^m (Y_{ij}-\\bar{Y}_i)^2 = \\sum_{i=1}^K\\sum_{j=1}^m Y_{ij}^2 -m\\sum_{i=1}^K\\bar{Y}_i^2$\n",
    "\n",
    "$SQ_{TCC} = \\sum_{j=1}^m (Y_{1j}-\\bar{Y}_1)^2 = 108$\n",
    "\n",
    "$SQ_{TPD} = \\sum_{j=1}^m (Y_{2j}-\\bar{Y}_2)^2 = 57.5$\n",
    "\n",
    "$SQ_{TN} = \\sum_{j=1}^m (Y_{3j}-\\bar{Y}_3)^2 = 143.333$\n",
    "\n",
    "$SQD = 108+57.5+143.333=308.83$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4311e-4acd-4b3e-923d-21b23f34a0a6",
   "metadata": {},
   "source": [
    "Agora você precisa da SQtotal, que representa a variabilidade total em todo o conjunto de dados. Você soma o variabilidade entre condições (isto é, SQE) e a variabilidade dentro das condições (isto é, SQD).\n",
    "\n",
    "$SQT = \\sum_{i=1}^K\\sum_{j=1}^m (Y_{ij}-\\bar{Y})^2 = \\sum_{i=1}^K\\sum_{j=1}^m Y_{ij}^2 -mK\\bar{Y}^2 = SQE + SQD = 252.78 + 308.83 = 561.61$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ad777-ac83-4628-8711-6a48d4787695",
   "metadata": {},
   "source": [
    "Seu objetivo final é calcular o F obtido, que é a razão entre QMentre e QMerro. Para calcular os QMs, você divide cada valor das SQ por seu próprio valor de gl.\n",
    "\n",
    "$QME = \\frac{SQE}{K-1}=\\frac{252.58}{2} = 126.39$\n",
    "\n",
    "$QMD = \\frac{SQD}{N-K}=\\frac{252.58}{15} = 20.59$\n",
    "\n",
    "Seu F obtido é calculado dividindo o QME pelo QMD:\n",
    "\n",
    "$F = \\frac{QME}{QMD} = \\frac{126.39}{20.59} = 6.138$\n",
    " \n",
    "A Tabela 11.4 é a tabela fonte da ANOVA para esta análise. Confirme que você entende como cada um os valores SQs, gls, QMs e F foram calculados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43d4b7-746f-4fcc-b6a9-7430c2388dae",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question8.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90938224-6432-49d7-8c1e-e311cfd446d0",
   "metadata": {},
   "source": [
    "Fonte de Variação | Graus de Liberdade | Soma de Quadrados | Quadrado Médio | F  \n",
    "-- | -- | -- | -- | --\n",
    "Entre | 2 | 258.72 | 126.39 | 6.14  \n",
    "Dentro | 15 | 308.83 | 20.59    \n",
    "Total | 17 | 561.61 |  |   \n",
    "\n",
    "Neste caso, o valor F obtido foi 6.14, que é superior ao valor F crítico de 3.68 (alpha = 0.05). Portanto, você rejeita a hipótese nula e conclui que pelo menos uma média amostral é significativamente diferente de uma das outras.\n",
    "\n",
    "_4e. Se necessário, calcule testes post hoc_\n",
    "\n",
    "A hipótese nula para uma ANOVA é que todas as diferentes médias das condições são iguais. Rejeitar o nulo não indica quais pares de médias são diferentes entre si. Assim, se você rejeitar a hipótese nula e houver três ou mais condições VI no estudo, será necessário realizar testes post hoc de pares para determinar qual par ou pares de médias são diferentes entre si. Neste caso, são necessárias três comparações aos pares. O grupo TCC precisa ser comparado com o grupo TFD e o grupo NT. Além disso, o grupo TFD precisa ser comparado com o grupo NT. A Figura 11.2 ilustra as três comparações post hoc para esta análise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6077173d-dde8-473f-a11c-b1e44950fc22",
   "metadata": {},
   "source": [
    "Existem vários testes post hoc diferentes que você pode usar. O que usamos ao longo deste livro é o teste de diferença honestamente significativa (HSD) de Tukey. O teste HSD revela quão diferentes devem ser quaisquer duas médias para serem consideradas \"improváveis de resultar de erro de amostragem\" (isto é, significativamente diferentes). Portanto, qualquer par de médias que difira mais do que o valor HSD é significativamente diferente. A fórmula HSD é\n",
    "\n",
    "$HSD = q\\sqrt{\\frac{SQD}{m}}$\n",
    "\n",
    "Você obtém o QMerror da tabela geral de resumo da ANOVA. Neste caso, QMerror = 20.59. O número de unidades amostrais dentro de cada condição de tratamento é _m_; neste caso, _m = 6_. O valor de q (chamado de estatística de faixa estudentizada) muda, com base no número de condições de tratamento (ou seja, K), o gl para o termo de erro e o valor alfa. Uma tabela de valores q está no Apêndice D. Nesse caso, g = 3, o gl para o termo de erro ($gl_{erro}$) = 15 e o nível alfa = 0.05. Com base nesses valores, a estatística q é 3.67.\n",
    "\n",
    "Assim, seu valor HSD é\n",
    "\n",
    "$HSD = q\\sqrt{\\frac{SQD}{n}}= 3.67\\sqrt{\\frac{20.59}{6}}=6.80$\n",
    "\n",
    "Agora você compara o valor HSD com o valor absoluto da diferença observada entre cada par de médias. Por exemplo, a diferença média entre as condições TCC e TFD é (8 - 15.5) = -7.5. O valor absoluto dessa diferença é maior que o valor HSD de 6.80. Consequentemente, o grupo TCC (M = 8) apresentou níveis de depressão significativamente mais baixos do que o grupo PDT (M = 15.5). Os dois testes _post hoc_ restantes estão resumidos na Tabela 11.5. Conforme indicado na tabela, diferenças significativas sugerem que a diferença não foi criada por erro amostral.\n",
    "\n",
    "Comparação | Diferença entre médias | Siginificância\n",
    "-- | -- | --\n",
    "TCC vs TPD | \\|8-15.5\\|=7.5 | >HSD - Significativo\n",
    "TCC vs NT | \\|8-16.33\\|=8.33 | >HSD - Significativo\n",
    "NT vs TPD | \\|15.5-16.33\\|=-0.83 | <HSD - Não Significativo\n",
    "\n",
    "Com base nessas análises, você pode concluir que o grupo da TCC teve pontuações de depressão significativamente mais baixas do que o grupo da TFD, sugerindo que a TCC é melhor para tratar a depressão do que a TPD. Da mesma forma, o grupo TCC apresentou depressão significativamente menor do que o grupo NT, sugerindo que a TCC é melhor que a NT. Finalmente, os grupos TPD e NT não foram significativamente diferentes. Uma diferença não significativa entre estas duas condições significa que a diferença é provavelmente criada por erro de amostragem. Portanto, estes resultados sugerem que a TPD não é melhor no tratamento da depressão do que nenhum tratamento. A fórmula HSD apresentada acima é apropriada apenas quando o número de observações dentro de cada condição de tratamento é o mesmo. Quando n é diferente dentro de cada condição, você calcula valores HSD separados para cada comparação entre pares. Usaremos _software_ para calcular os valores HSD quando for o caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e6a1b-4d85-4c05-ba2b-e21908bf8dd4",
   "metadata": {},
   "source": [
    "_Etapa 5: calcule o tamanho do efeito e descreva-o_\n",
    "\n",
    "Quando você tem dois grupos, usa d como medida do tamanho do efeito. Você não pode usar d como medida do tamanho do efeito para uma ANOVA geral porque geralmente há mais de dois grupos, então você não pode calcular uma diferença média simples. O tamanho do efeito mais comum para ANOVAs é eta parcial quadrado  ($\\eta_p^2$). Os cálculos são os seguintes:\n",
    "\n",
    "$\\eta_p^2 = \\frac{SQE}{SQE+SQD}=\\frac{252.78}{252.78+308.83}=0.45$\n",
    "\n",
    "Para ANOVAs de um fator, você deve interpretar o eta parcial quadrado como a porcentagem da variabilidade VD que a VI \"explica\". Neste caso, o tipo de tratamento que os participantes recebem \"explica\" 45% da variabilidade nos seus valores de depressão. Num contexto estatístico, a percentagem de variabilidade que uma VI \"explica\" é a percentagem de variância de VD que está associada a mudanças no tipo de tratamento que os participantes receberam. Se uma VI (isto é, tratamentos diferentes) explica 45% da variabilidade numa VD (ou seja, pontuações de depressão), os restantes 55% da variabilidade são \"explicados\" por erro. Quando estudos de pesquisa semelhantes não estiverem disponíveis para fornecer uma comparação relativa, use as diretrizes na Tabela 11.6 para interpretar o tamanho de ($\\eta_p^2$). O tamanho do efeito obtido de 0.45 é maior que 0.14 e, portanto, é um efeito grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3c7be-e310-412b-847e-edb723750aa8",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "display_quiz(\"question9.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd5492-1952-41ac-820e-f5f28fc28a45",
   "metadata": {},
   "source": [
    "Você pode descobrir que essa medida do tamanho do efeito, eta parcial ao quadrado, às vezes é chamada de eta ao quadrado. Embora seja verdade que para ANOVAs de um fator, eta ao quadrado e eta parcial ao quadrado  produzem valores idênticos, na verdade são estatísticas diferentes. A distinção torna-se mais importante quando se trabalha com experimentos fatoriais mais complexos descritos no próximo capítulo. Usamos eta ao quadrado parcial neste livro. O eta parcial quadrado fornece um tamanho de efeito para a ANOVA geral. No exemplo da depressão, representa que 45% da variabilidade nas pontuações de depressão pode ser explicada pelo tipo de tratamento que os participantes receberam. Isso indica que o tipo de tratamento teve um grande efeito nos valores de depressão. No entanto, o eta parcial quadrado  não descreve o tamanho dos efeitos para as comparações aos pares. Nesse caso, há três comparações aos pares, e você precisa calcular um tamanho de efeito para cada comparação para saber o quanto cada tipo de tratamento foi mais eficaz do que os outros tratamentos. Para os tamanhos de efeito dessas comparações de pares, você pode usar o mesmo d usado para o t independente:\n",
    "\n",
    "\n",
    "\n",
    "Como lembrete, as médias e os desvios padrão para cada grupo são fornecidos na Tabela 11.7. Para cada comparação pareada, você calcula a diferença média e depois divide pelos desvios padrão agrupados para os dois grupos. Os tamanhos de efeito para d são interpretados da mesma forma que nos capítulos anteriores (ou seja, 0,2 é pequeno, 0,5 é médio e 0,8 é grande). Esses ds pareados indicam que a TCC foi muito mais eficaz que a TFD (d = 1,84) e a NT (d = 1,66). Se você fosse um psicólogo clínico TCC 8,00 (4,65) tentando encontrar a melhor maneira de ajudar seus clientes, essas estatísticas seriam extremamente úteis, indicando que a CBT era de longe o tratamento mais eficaz para seus clientes. Depois de ver esses resultados, você deveria estar pensando que a TCC é a terapia mais apoiada pelas evidências da pesquisa. Mas, como mencionado anteriormente, o tamanho da amostra deste estudo é demasiado pequeno para tirar conclusões firmes. O estudo anterior pode ser considerado um estudo piloto que sugere que vale a pena fazer um estudo maior.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf1560e-e66d-46f0-8108-1af42dae7c25",
   "metadata": {},
   "source": [
    "### Etapa 6: resumir os resultados\n",
    "\n",
    "Ao relatar uma ANOVA, você deve relatar gl_entre, gl_error, o valor F obtido, o valor p, QME, n2p e o ds individuais para as comparações aos pares. Você também deve indicar quais condições de tratamento foram significativamente diferentes uns dos outros. As médias, desvios padrão e tamanhos de efeito para as comparações aos pares são relatados em tabelas, portanto não precisam ser repetidos no texto. O que se segue é um exemplo de como a análise acima pode ser resumida.\n",
    "\n",
    "Uma ANOVA independente revelou diferenças significativas entre as três terapias para depressão, F(2, 15) = 6.14, p < 0.05, $\\eta_p^2 = 0.45$, QME = 20.59. As médias e desvios padrão para cada tratamento estão na Tabela 11.9. Os testes _post hoc_ do HSD de Tukey revelaram que o grupo da TCC apresentou valores de depressão mais baixos do que o grupo PDT e o grupo sem tratamento. A terapia PDT não foi melhor do que não receber nenhum tratamento. Os testes post hoc do HSD e seus tamanhos de efeito estão na Tabela 11.10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0c361-35ec-44cc-86c0-fac5cd54db7d",
   "metadata": {},
   "source": [
    "## Uma nota adicional sobre ANOVAS\n",
    " \n",
    "Você pode estar se perguntando por que nos preocupamos com se vamos apenas fazer testes post hoc em pares depois de fazer uma ANOVA. Por que não fazemos testes t para comparar todos os pares de médias? A resposta está na taxa de erro do estudo (frequentemente chamada de erro familiar - _family-wise error rate_ (FWER) é a probabilidade de obter um ou mais falso posivitos). Ao definir o nível alfa de um teste como 0,05, você está definindo a taxa de erro tipo I de 5%. Um erro Tipo I é a probabilidade de dizer que um tratamento funcionou quando na verdade não funcionou. No entanto, se você fizer vários testes t, cada teste t terá 5% de chance de produzir um erro Tipo I. Se você realizar vários testes t, a probabilidade exata de ter cometido pelo menos um erro Tipo I é dada pela seguinte fórmula de erro familiar\n",
    "\n",
    "$FWER = 1-(1-\\alpha)^c$, onde c é o número de comparações\n",
    "\n",
    "Se você tiver apenas uma comparação, a taxa de erro Tipo I seria\n",
    "\n",
    "$FWER = 1 - (1-0.05)^1 = 0.05$ ou 5%.\n",
    "\n",
    "No entanto, se você tiver três comparações no mesmo estudo, a probabilidade de ter cometido pelo menos um erro Tipo I é um pouco maior, 0,14 ou 14%.\n",
    "\n",
    "$FWER = 1 - (1 - 0.05)^3 = 0.14$.\n",
    "\n",
    "Fazer uma única ANOVA em vez de vários testes t mantém a taxa de erro familiar em 0.05 para a ANOVA geral. Se forem necessários testes _post hoc_, há uma variedade de testes para escolher, mas a ideia geral por trás da maioria deles é que eles evitam que a taxa de erro Tipo I aumente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf8f12-9e5e-48db-b9de-354377063eab",
   "metadata": {},
   "source": [
    "## Prática complementar OPCIONAL\n",
    "\n",
    "Código python: [![Abra com Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/ridasilva/bioestatisca/blob/master/capitulos/chap11/chap11anova.ipynb)\n",
    "\n",
    "Google Planilhas: [![Abra com Colab](../chap5/fig/google_sheet.png)](https://docs.google.com/spreadsheets/d/1-7qaAk6d1a3IL7huaGC8o4PrYNhcFEHHXJcdWvowvKY/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db79171-36ff-4705-a534-d56bb284f9f9",
   "metadata": {},
   "source": [
    "## Bibliografia\n",
    "\n",
    "```{bibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
